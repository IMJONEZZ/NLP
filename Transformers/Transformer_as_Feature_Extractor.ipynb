{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset emotion (C:\\Users\\chris\\.cache\\huggingface\\datasets\\emotion\\default\\0.0.0\\348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label label_name\n",
       "0                            i didnt feel humiliated      0    sadness\n",
       "1  i can go from feeling so hopeless to so damned...      0    sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong      3      anger\n",
       "3  i am ever feeling nostalgic about the fireplac...      2       love\n",
       "4                               i am feeling grouchy      3      anger"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"emotion\")\n",
    "ds.set_format(type=\"pandas\")\n",
    "df = ds['train'][:]\n",
    "\n",
    "def label_int2str(row):\n",
    "    return ds['train'].features['label'].int2str(row)\n",
    "\n",
    "df['label_name'] = df['label'].apply(label_int2str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModel.from_pretrained(model_ckpt).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16000/16000 [00:15<00:00, 1017.55ex/s]\n",
      "100%|██████████| 2000/2000 [00:01<00:00, 1017.27ex/s]\n",
      "100%|██████████| 2000/2000 [00:01<00:00, 1023.53ex/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': Value(dtype='string', id=None), 'label': ClassLabel(num_classes=6, names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'], names_file=None, id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "    if type(batch['text']) == \"str\":\n",
    "        return tokenizer(batch['text'], padding=True, truncation=True)\n",
    "    else:\n",
    "        text = str(batch['text'])\n",
    "        return tokenizer(text, padding=True, truncation=True)\n",
    "\n",
    "enc_ds = ds.map(tokenize, load_from_cache_file=False)\n",
    "print(enc_ds['train'].features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16000 [00:00<?, ?ba/s]<ipython-input-12-377c6ffa2fec>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = {k:torch.tensor(v).to(\"cuda\") for k,v in batch.items() if k in tokenizer.model_input_names}\n",
      "100%|██████████| 16000/16000 [01:41<00:00, 158.00ba/s]\n",
      "100%|██████████| 2000/2000 [00:12<00:00, 163.95ba/s]\n",
      "100%|██████████| 2000/2000 [00:12<00:00, 164.42ba/s]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.model_input_names)\n",
    "def extract_hidden_states(batch):\n",
    "    inputs = {k:torch.tensor(v).to(\"cuda\") for k,v in batch.items() if k in tokenizer.model_input_names}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs).last_hidden_state\n",
    "    return {\"hidden_state\": outputs[:,0].cpu().numpy()}\n",
    "    \n",
    "enc_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "ds_hidden = enc_ds.map(extract_hidden_states, batched=True, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])], 'hidden_state': tensor([[-0.2062,  0.3054,  0.1314,  ...,  0.3351,  0.0351, -0.4032],\n",
      "        [-0.0041,  0.3205, -0.0872,  ...,  0.1761, -0.0223, -0.3161],\n",
      "        [-0.2710,  0.3522,  0.0447,  ...,  0.2467,  0.1068, -0.3156],\n",
      "        [ 0.0905,  0.5637, -0.3885,  ...,  0.1472, -0.2884, -0.1310],\n",
      "        [-0.0049,  0.1839, -0.0715,  ...,  0.2255, -0.0468, -0.2650]]), 'input_ids': [tensor([  101,  1014,  1045,  2134,  2102,  2514, 26608,  2171,  1024,  3793,\n",
      "         1010, 26718, 18863,  1024,  4874,   102]), tensor([  101,  1014,  1045,  2064,  2175,  2013,  3110,  2061, 20625,  2000,\n",
      "         2061,  9636,  1012,  1012,  1012,  2171,  1024,  3793,  1010, 26718,\n",
      "        18863,  1024,  4874,   102]), tensor([  101,  1014, 10047,  9775,  1037,  3371,  2000,  2695,  1045,  2514,\n",
      "        20505,  3308,  2171,  1024,  3793,  1010, 26718, 18863,  1024,  4874,\n",
      "          102]), tensor([  101,  1014,  1045,  2572,  2412,  3110, 16839,  9080, 12863,  2055,\n",
      "         1996,  2543, 24759,  6305,  1012,  1012,  1012,  2171,  1024,  3793,\n",
      "         1010, 26718, 18863,  1024,  4874,   102]), tensor([  101,  1014,  1045,  2572,  3110, 24665,  7140, 11714,  2171,  1024,\n",
      "         3793,  1010, 26718, 18863,  1024,  4874,   102])], 'label': tensor([0, 0, 3, 2, 3])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\datasets\\formatting\\formatting.py:167: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(array, copy=False, **self.np_array_kwargs)\n"
     ]
    }
   ],
   "source": [
    "print(ds_hidden['train'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 384) (2000, 384)\n",
      "(16000,) (2000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(ds_hidden['train']['hidden_state'])\n",
    "X_valid = np.array(ds_hidden['validation']['hidden_state'])\n",
    "Y_train = np.array(ds_hidden['train']['label'])\n",
    "Y_valid = np.array(ds_hidden['validation']['label'])\n",
    "print(X_train.shape, X_valid.shape)\n",
    "print(Y_train.shape, Y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-39.538387</td>\n",
       "      <td>3.298877</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-16.601639</td>\n",
       "      <td>8.595325</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-33.169800</td>\n",
       "      <td>-60.807358</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.395744</td>\n",
       "      <td>53.454262</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-32.307083</td>\n",
       "      <td>43.052593</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           X          Y  label\n",
       "0 -39.538387   3.298877      0\n",
       "1 -16.601639   8.595325      0\n",
       "2 -33.169800 -60.807358      3\n",
       "3  28.395744  53.454262      2\n",
       "4 -32.307083  43.052593      3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled = MinMaxScaler().fit_transform(X_train)\n",
    "mapper = TSNE(n_components=2, metric=\"cosine\").fit(X_scaled)\n",
    "df_embed = pd.DataFrame(mapper.embedding_, columns=[\"X\",\"Y\"])\n",
    "df_embed['label'] = Y_train\n",
    "df_embed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.561"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(max_iter=3000)\n",
    "lr_clf.fit(X_train, Y_train)\n",
    "lr_clf.score(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3515"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_embed[[\"X\",\"Y\"]]\n",
    "lr_feature_clf = LogisticRegression(max_iter=3000)\n",
    "lr_feature_clf.fit(X, df_embed['label'])\n",
    "lr_feature_clf.score(X, df_embed['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.335125"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train, Y_train)\n",
    "dummy_clf.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7433d19ec64a94f983d045b195f492572faef5136675c629b63ea1de2ae5e1b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
