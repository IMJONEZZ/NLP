{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig, DataCollator, TrainingArguments, Trainer\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "import torch\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('amazon_reviews_multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric('accuracy')\n",
    "f1_metric = load_metric('f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_shard=True\n",
    "if do_shard:\n",
    "    dataset = dataset.shuffle(seed=8855)\n",
    "    train_dataset=dataset[\"train\"].shard(index=1, num_shards=10)\n",
    "    val_dataset=dataset[\"validation\"].shard(index=1, num_shards=5)\n",
    "else:\n",
    "    train_dataset=dataset[\"train\"]\n",
    "    val_dataset=dataset[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint='./model'\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_to_max=False\n",
    "def tokenize_data(example):\n",
    "    text_ = example[\"review_body\"] + \" \" + example[\"review_title\"] + \" \" + example[\"product_category\"]\n",
    "    encodings = tokenizer(text_, pad_to_max_length=pad_to_max,\n",
    "                                truncation=True,\n",
    "                                add_special_tokens=True,\n",
    "                                return_token_type_ids=False,\n",
    "                                return_attention_mask=True,\n",
    "                                return_overflowing_tokens=False,\n",
    "                                return_special_tokens_mask=False,\n",
    "                                )\n",
    "    encodings[\"labels\"] = example[\"stars\"] - 1\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train_dataset = train_dataset.map(tokenize_data)\n",
    "encoded_val_dataset = val_dataset.map(tokenize_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(seq, max_batch_len, pad_value):\n",
    "    return seq + (max_batch_len - len(seq)) * [pad_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SmartCollator():\n",
    "    pad_token_id: int\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        batch_inputs = list()\n",
    "        batch_attention_mask = list()\n",
    "        labels = list()\n",
    "        max_size = max(len(ex['input_ids']) for ex in batch)\n",
    "        for item in batch:\n",
    "            batch_inputs += [pad_seq(item['input_ids'], max_size, self.pad_token_id)]\n",
    "            batch_attention_mask += [pad_seq(item['attention_mask'], max_size, 0)]\n",
    "            labels.append(item['labels'])\n",
    "        \n",
    "        return {\"input_ids\": torch.tensor(batch_inputs, dtype=torch.long),\n",
    "                \"attention_mask\": torch.tensor(batch_attention_mask, dtype=torch.long),\n",
    "                \"labels\": torch.tensor(labels, dtype=torch.long)\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "NUM_LABELS = 5\n",
    "\n",
    "resume_training = True\n",
    "if resume_training:\n",
    "    model_checkpoint = './model'\n",
    "else:\n",
    "    model_checkpoint = 'xlm-roberta-base'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=NUM_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_NAME = 'accuracy'\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir='./model',\n",
    "    seed=8855,\n",
    "    evaluation_strategy='steps',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=METRIC_NAME,\n",
    "    eval_steps=5000,\n",
    "    save_steps=5000,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return metric.compute(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_key = \"validation\"\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_val_dataset,\n",
    "    data_collator=SmartCollator(pad_token_id=tokenizer.pad_token_id),\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
