{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(8855)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 1.7630e-02, -1.0847e-01, -1.5039e-01, -9.7330e-03,  2.0457e-03,\n",
      "           8.5873e-02, -8.5565e-02,  4.7221e-02, -1.9621e-02, -1.3914e-02,\n",
      "          -8.8130e-02,  2.4225e-02, -1.6868e-02,  2.7444e-02, -3.7166e-02,\n",
      "           5.5170e-02,  1.4409e-01,  1.3244e-01,  1.0878e-01,  2.8372e-02],\n",
      "         [-7.7712e-02, -8.6543e-02, -3.5389e-02,  1.5973e-02, -2.7933e-03,\n",
      "           9.0377e-02, -6.2036e-02,  5.2811e-02, -6.2467e-02, -6.9249e-02,\n",
      "           1.8516e-03,  1.1086e-01, -4.1779e-02, -1.3126e-01, -3.4962e-02,\n",
      "          -4.7682e-03,  8.7910e-02, -5.0262e-02, -2.5815e-02, -6.2216e-02],\n",
      "         [ 1.4144e-01, -6.1399e-03, -1.3166e-01,  7.1492e-02,  1.1627e-01,\n",
      "           8.5660e-03, -7.2213e-02,  2.0786e-02, -2.3399e-02, -5.9867e-02,\n",
      "          -5.1596e-03,  1.9993e-01,  4.3648e-03,  8.0428e-02,  3.9716e-02,\n",
      "           1.4804e-01,  8.1765e-02, -1.1661e-01, -1.0176e-01,  1.0283e-01]],\n",
      "\n",
      "        [[-4.0178e-02, -1.4586e-01, -5.1796e-02, -1.1073e-02,  3.8176e-02,\n",
      "           2.1209e-01, -3.0734e-04,  1.7552e-01, -4.6032e-02,  3.4580e-02,\n",
      "           1.2390e-01,  1.6596e-01,  1.5580e-01,  1.5463e-01,  1.0131e-01,\n",
      "          -8.0016e-04,  2.6621e-03,  1.9127e-02,  7.8555e-02, -9.4147e-02],\n",
      "         [-2.3365e-01,  6.4645e-02,  5.9222e-03, -8.7029e-02,  4.3277e-02,\n",
      "           2.7572e-01, -1.0986e-01,  3.6000e-01,  8.7305e-02,  3.5026e-02,\n",
      "           2.1204e-01,  1.6519e-01, -3.3774e-02, -2.7216e-02,  2.2802e-02,\n",
      "           8.5044e-02, -1.1332e-02, -1.2432e-01,  8.8388e-02, -1.1388e-01],\n",
      "         [-1.2170e-03, -9.3915e-02, -1.5428e-01,  1.0090e-01,  2.5537e-02,\n",
      "          -4.4407e-04, -2.6775e-02,  8.5423e-02,  3.1268e-02,  1.8214e-02,\n",
      "          -3.7326e-02,  2.9200e-01,  2.1692e-02, -2.4199e-02,  6.1492e-02,\n",
      "          -1.7141e-02,  1.0975e-01, -9.7453e-02, -2.4268e-02, -1.3270e-01]],\n",
      "\n",
      "        [[ 2.0566e-02, -7.4126e-02, -1.0101e-01, -6.7417e-02,  1.7419e-01,\n",
      "           1.4161e-01, -6.0020e-02,  1.4336e-01, -1.1619e-01, -3.7624e-02,\n",
      "           2.0102e-01,  1.4524e-01,  6.5889e-02,  7.9668e-02,  1.2837e-01,\n",
      "           1.0966e-01,  8.8980e-02, -7.8735e-02, -6.5010e-02, -6.2301e-02],\n",
      "         [-1.6204e-01,  1.2155e-02,  6.4525e-02, -1.3737e-01, -1.1326e-03,\n",
      "           2.7704e-01, -2.1792e-01,  2.7479e-01, -4.5300e-02,  2.8969e-02,\n",
      "           3.3588e-01,  8.5264e-02, -5.6238e-05,  4.4387e-02,  1.3767e-01,\n",
      "           6.7639e-02, -6.0449e-02, -5.4797e-02,  6.8032e-02, -2.2961e-01],\n",
      "         [-9.0671e-02, -6.3235e-02, -2.4665e-01, -1.2138e-01, -1.1941e-01,\n",
      "           1.1916e-01, -1.1849e-01,  2.3518e-01,  6.2622e-02,  3.7032e-02,\n",
      "           2.9918e-03,  1.2499e-01,  9.2162e-03, -1.2134e-02,  6.9332e-02,\n",
      "          -2.0891e-02,  7.8564e-02, -5.5101e-02,  6.8689e-02, -2.1522e-01]],\n",
      "\n",
      "        [[ 1.3219e-01, -1.2767e-02, -5.8190e-02,  2.2118e-01,  1.1494e-01,\n",
      "           3.6794e-02, -2.9554e-03, -3.6230e-02, -2.5739e-01, -1.7365e-01,\n",
      "           4.8643e-02,  3.1083e-01,  1.9472e-01,  2.8623e-01,  4.9870e-02,\n",
      "           1.9350e-01,  6.5013e-02,  4.0153e-02, -6.0295e-02,  1.0734e-01],\n",
      "         [ 2.7459e-02, -8.8954e-02, -5.0439e-02, -2.7816e-01,  9.5950e-02,\n",
      "           1.4838e-01, -2.4126e-01,  3.2983e-02, -8.1205e-03,  2.1719e-04,\n",
      "           7.0113e-02,  1.2531e-03,  1.2987e-01,  1.1859e-01,  1.4607e-01,\n",
      "           7.3183e-02,  3.1621e-02,  9.2493e-02,  5.7167e-02, -3.4450e-02],\n",
      "         [-2.9480e-02, -9.4498e-02, -6.7899e-02, -2.1016e-01, -1.7040e-01,\n",
      "           2.1800e-01, -2.2433e-01,  1.6245e-01,  5.4372e-02,  3.6679e-02,\n",
      "           3.1814e-02,  5.0400e-02,  1.0379e-01,  1.3239e-01,  9.1575e-02,\n",
      "           8.4877e-03,  1.4081e-02,  2.8363e-02,  1.4807e-01, -1.1280e-01]],\n",
      "\n",
      "        [[ 1.4425e-01,  3.9869e-02, -2.2772e-02,  2.4538e-01,  1.3757e-01,\n",
      "           5.4857e-03,  1.1640e-01, -8.0478e-02, -2.3948e-01, -1.0779e-01,\n",
      "           8.0569e-02,  3.0488e-01,  3.4420e-01,  2.3917e-01,  5.8822e-02,\n",
      "           1.2910e-01,  4.9375e-02,  5.9406e-02, -6.0741e-02,  8.2896e-02],\n",
      "         [ 1.2172e-01, -7.0654e-02, -1.2415e-01, -1.4335e-01,  1.4422e-01,\n",
      "           6.0888e-02, -2.0704e-01, -6.6690e-02, -2.3919e-02, -6.9855e-02,\n",
      "          -7.7891e-02,  6.3835e-02,  9.7252e-02, -6.6164e-02,  6.5596e-02,\n",
      "           1.7653e-01,  1.3700e-01,  2.4756e-02, -1.9496e-02,  1.0059e-01],\n",
      "         [ 8.4622e-02, -1.1893e-01, -7.0839e-03, -1.1887e-01,  3.2937e-02,\n",
      "           1.4445e-01, -1.5609e-01, -8.6034e-03, -6.5155e-02, -2.9248e-02,\n",
      "           3.8075e-02,  1.0720e-01,  2.3453e-01,  1.0883e-01,  9.5720e-02,\n",
      "           9.4477e-02, -5.9563e-03, -2.5246e-02,  1.7763e-02,  5.8863e-02]]],\n",
      "       grad_fn=<StackBackward0>), (tensor([[[ 0.1443,  0.0399, -0.0228,  0.2454,  0.1376,  0.0055,  0.1164,\n",
      "          -0.0805, -0.2395, -0.1078,  0.0806,  0.3049,  0.3442,  0.2392,\n",
      "           0.0588,  0.1291,  0.0494,  0.0594, -0.0607,  0.0829],\n",
      "         [ 0.1217, -0.0707, -0.1242, -0.1433,  0.1442,  0.0609, -0.2070,\n",
      "          -0.0667, -0.0239, -0.0699, -0.0779,  0.0638,  0.0973, -0.0662,\n",
      "           0.0656,  0.1765,  0.1370,  0.0248, -0.0195,  0.1006],\n",
      "         [ 0.0846, -0.1189, -0.0071, -0.1189,  0.0329,  0.1445, -0.1561,\n",
      "          -0.0086, -0.0652, -0.0292,  0.0381,  0.1072,  0.2345,  0.1088,\n",
      "           0.0957,  0.0945, -0.0060, -0.0252,  0.0178,  0.0589]]],\n",
      "       grad_fn=<StackBackward0>), tensor([[[ 0.3864,  0.0598, -0.0572,  0.4471,  0.3233,  0.0187,  0.2244,\n",
      "          -0.2780, -0.4623, -0.1527,  0.1348,  0.4808,  0.4708,  0.5047,\n",
      "           0.1768,  0.2203,  0.1176,  0.1202, -0.1324,  0.2536],\n",
      "         [ 0.2927, -0.1678, -0.2924, -0.2021,  0.4318,  0.1818, -0.4162,\n",
      "          -0.2012, -0.0595, -0.1174, -0.1524,  0.1262,  0.1574, -0.1127,\n",
      "           0.1566,  0.4292,  0.3467,  0.0531, -0.0442,  0.2216],\n",
      "         [ 0.1891, -0.2369, -0.0176, -0.2017,  0.0683,  0.4330, -0.3655,\n",
      "          -0.0210, -0.1272, -0.0431,  0.0661,  0.2300,  0.3351,  0.2165,\n",
      "           0.2515,  0.1825, -0.0137, -0.0539,  0.0344,  0.1463]]],\n",
      "       grad_fn=<StackBackward0>)))\n"
     ]
    }
   ],
   "source": [
    "lstm = torch.nn.LSTM(10,20,1)\n",
    "stuff = torch.randn(5,3,10)\n",
    "output = lstm(stuff)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n",
      "tensor([[[0.0618, 0.0551, 0.0568,  ..., 0.0668, 0.0621, 0.0539],\n",
      "         [0.0612, 0.0563, 0.0558,  ..., 0.0650, 0.0629, 0.0571],\n",
      "         [0.0602, 0.0527, 0.0576,  ..., 0.0621, 0.0654, 0.0583],\n",
      "         ...,\n",
      "         [0.0615, 0.0515, 0.0595,  ..., 0.0639, 0.0626, 0.0539],\n",
      "         [0.0610, 0.0515, 0.0595,  ..., 0.0641, 0.0627, 0.0540],\n",
      "         [0.0601, 0.0516, 0.0594,  ..., 0.0647, 0.0631, 0.0539]]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>) torch.Size([1, 128, 17])\n",
      "tensor([0.0618, 0.0551, 0.0568, 0.0578, 0.0551, 0.0655, 0.0542, 0.0567, 0.0605,\n",
      "        0.0664, 0.0631, 0.0552, 0.0539, 0.0552, 0.0668, 0.0621, 0.0539],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "target_classes = ['O','B-geo','B-gpe','B-per','I-geo','B-org','I-org','B-tim','B-art','I-art','I-per','I-gpe','I-tim','B-nat','B-eve','I-eve','I-nat']\n",
    "\n",
    "class LSTMClassifier(torch.nn.Module):\n",
    "    def __init__(self, embedding, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding_layer = torch.nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding)\n",
    "        self.lstm = torch.nn.LSTM(input_size=embedding, hidden_size=hidden_dim, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.dense = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim*2, hidden_dim),\n",
    "            torch.nn.GELU(),\n",
    "            torch.nn.Linear(hidden_dim, tagset_size)\n",
    "        )\n",
    "        self.soft = torch.nn.Softmax(dim=2)\n",
    "        \n",
    "    def forward(self, X_batch):\n",
    "        X_batch = X_batch.to(device)\n",
    "        embeddings = self.embedding_layer(X_batch)\n",
    "        embeddings = embeddings.float().requires_grad_()\n",
    "        output, _ = self.lstm(embeddings)\n",
    "        out = self.dense(output)\n",
    "        soft = self.soft(out)\n",
    "        return soft\n",
    "        \n",
    "lstm_classifier = LSTMClassifier(128, 75, 35181, len(target_classes)).to(device)\n",
    "\n",
    "input = torch.tensor([[  345,   134,  1470,   363,    31,     9,    16,  7202,  2280,    93,  4268,   172,\n",
    "    35,     9,  9063,     1,  3243,    78, 13429,  3123,    21,    35, 35180, 35180,\n",
    " 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180,\n",
    " 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180,\n",
    " 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180,\n",
    " 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180,\n",
    " 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180,\n",
    " 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180,\n",
    " 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180,\n",
    " 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180,\n",
    " 35180, 35180, 35180, 35180, 35180, 35180, 35180, 35180,]])\n",
    "print(input.shape)\n",
    "out = lstm_classifier(input)\n",
    "print(out, out.shape)\n",
    "print(out[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(vocab_path, tags_path):\n",
    "    vocab = {}\n",
    "    with open(vocab_path, encoding=\"ISO-8859-1\") as f:\n",
    "        for i, l in enumerate(f.read().splitlines()):\n",
    "            vocab[l] = i \n",
    "    vocab['<PAD>'] = len(vocab)\n",
    "    tag_map = {}\n",
    "    with open(tags_path, encoding=\"ISO-8859-1\") as f:\n",
    "        for i, t in enumerate(f.read().splitlines()):\n",
    "            tag_map[t] = i\n",
    "            \n",
    "    return vocab, tag_map\n",
    "\n",
    "def get_params(vocab, tag_map, sentences_file, labels_file):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    \n",
    "    with open(sentences_file, encoding=\"ISO-8859-1\") as f:\n",
    "        for sentence in f.read().splitlines():\n",
    "            s = [vocab[token] if token in vocab\n",
    "                 else vocab['UNK']\n",
    "                 for token in sentence.split(' ')]\n",
    "            sentences.append(s)\n",
    "            \n",
    "    with open(labels_file, encoding=\"ISO-8859-1\") as f:\n",
    "        for sentence in f.read().splitlines():\n",
    "            l = [tag_map[label] for label in sentence.split(' ')]\n",
    "            labels.append(l)\n",
    "    return sentences, labels, len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 9, 15, 1, 16, 17, 18, 19, 20, 21] [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0] 33570\n"
     ]
    }
   ],
   "source": [
    "vocab, tag_map = get_vocab(\"./words.txt\", \"./tags.txt\")\n",
    "t_sentences, t_labels, t_size = get_params(vocab, tag_map, './train/sentences.txt', './train/labels.txt')\n",
    "print(t_sentences[0], t_labels[0], t_size)\n",
    "test_sentences, test_labels, test_size = get_params(vocab, tag_map, './test/sentences.txt', './test/labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(batch_size, x, y, pad, shuffle=False, verbose=False):\n",
    "    '''\n",
    "      Input: \n",
    "        batch_size - integer describing the batch size\n",
    "        x - list containing sentences where words are represented as integers\n",
    "        y - list containing tags associated with the sentences\n",
    "        shuffle - Shuffle the data order\n",
    "        pad - an integer representing a pad character\n",
    "        verbose - Print information during runtime\n",
    "      Output:\n",
    "        a tuple containing 2 elements:\n",
    "        X - np.ndarray of dim (batch_size, max_len) of padded sentences\n",
    "        Y - np.ndarray of dim (batch_size, max_len) of tags associated with the sentences in X\n",
    "    '''\n",
    "    \n",
    "    # count the number of lines in data_lines\n",
    "    num_lines = len(x)\n",
    "    \n",
    "    # create an array with the indexes of data_lines that can be shuffled\n",
    "    lines_index = [*range(num_lines)]\n",
    "    \n",
    "    # shuffle the indexes if shuffle is set to True\n",
    "    if shuffle:\n",
    "        random.shuffle(lines_index)\n",
    "    \n",
    "    index = 0 # tracks current location in x, y\n",
    "    while True:\n",
    "        buffer_x = [0] * batch_size # Temporal array to store the raw x data for this batch\n",
    "        buffer_y = [0] * batch_size # Temporal array to store the raw y data for this batch\n",
    "                \n",
    "        \n",
    "        # Copy into the temporal buffers the sentences in x[index : index + batch_size] \n",
    "        # along with their corresponding labels y[index : index + batch_size]\n",
    "        # Find maximum length of sentences in x[index : index + batch_size] for this batch. \n",
    "        # Reset the index if we reach the end of the data set, and shuffle the indexes if needed.\n",
    "        max_len = 128\n",
    "        for i in range(batch_size):\n",
    "             # if the index is greater than or equal to the number of lines in x\n",
    "            if index >= num_lines:\n",
    "                # then reset the index to 0\n",
    "                index = 0\n",
    "                # re-shuffle the indexes if shuffle is set to True\n",
    "                if shuffle:\n",
    "                    random.shuffle(lines_index)\n",
    "            \n",
    "            # The current position is obtained using `lines_index[index]`\n",
    "            # Store the x value at the current position into the buffer_x\n",
    "            buffer_x[i] = x[lines_index[index]]\n",
    "            \n",
    "            # Store the y value at the current position into the buffer_y\n",
    "            buffer_y[i] = y[lines_index[index]]\n",
    "            \n",
    "            lenx = len(buffer_x[i])    #length of current x[]\n",
    "            if lenx > max_len:\n",
    "                max_len = lenx                   #max_len tracks longest x[]\n",
    "            \n",
    "            # increment index by one\n",
    "            index += 1\n",
    "\n",
    "\n",
    "        # create X,Y, NumPy arrays of size (batch_size, max_len) 'full' of pad value\n",
    "        X = np.full((batch_size, max_len), pad)\n",
    "        Y = np.full((batch_size, max_len, 17), pad)\n",
    "\n",
    "        # copy values from lists to NumPy arrays. Use the buffered values\n",
    "        for i in range(batch_size):\n",
    "            # get the example (sentence as a tensor)\n",
    "            # in `buffer_x` at the `i` index\n",
    "            x_i = buffer_x[i]\n",
    "            \n",
    "            # similarly, get the example's labels\n",
    "            # in `buffer_y` at the `i` index\n",
    "            y_i = buffer_y[i]\n",
    "            \n",
    "            # Walk through each word in x_i\n",
    "            for j in range(len(x_i)):\n",
    "                # store the word in x_i at position j into X\n",
    "                X[i, j] = x_i[j]\n",
    "                \n",
    "                # store the label in y_i at position j into Y\n",
    "                Y[i, j] = y_i[j]\n",
    "                \n",
    "                # one hot encode 3rd dim\n",
    "                for k in range(17):\n",
    "                    if k == y_i[j]:\n",
    "                        Y[i, j, k] = 1\n",
    "                    else:\n",
    "                        Y[i, j, k] = 0       \n",
    "\n",
    "        if verbose: print(\"index=\", index)\n",
    "        yield((X,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 128) (64, 128, 17)\n"
     ]
    }
   ],
   "source": [
    "train_loader = data_generator(64, t_sentences, t_labels, vocab[\"<PAD>\"],True)\n",
    "test_loader = data_generator(64, test_sentences, test_labels, vocab[\"<PAD>\"],True)\n",
    "\n",
    "for X,Y in train_loader:\n",
    "    print(X.shape, Y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compare(model, loss_fn, test_loader):\n",
    "    with torch.no_grad():\n",
    "        Y_shuffled, Y_preds, losses = [], [], []\n",
    "        its = 0\n",
    "        for X, Y in tqdm(test_loader):\n",
    "            X = torch.Tensor(X).to(device).long()\n",
    "            Y = torch.FloatTensor(Y).to(device)\n",
    "            preds = model(X)\n",
    "            loss = loss_fn(preds, Y)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            Y_shuffled.append(Y)\n",
    "            Y_preds.append(preds)\n",
    "            its += 1\n",
    "            if its > 7194:\n",
    "                break\n",
    "            \n",
    "        Y_shuffled = torch.cat(Y_shuffled)\n",
    "        Y_preds = torch.cat(Y_preds)\n",
    "        \n",
    "        print(f\"Validation Loss: {torch.tensor(losses).mean():.3f}\")\n",
    "        mask = Y_shuffled.detach().cpu().numpy() != vocab[\"<PAD>\"]\n",
    "        \n",
    "        acc = np.sum((Y_preds.detach().cpu().numpy() == Y_shuffled.detach().cpu().numpy()) * mask) / np.sum(mask)\n",
    "        print(f\"Validation Accuracy: {acc}\")\n",
    "            \n",
    "def TrainingLoop(model, loss_fn, optimizer, train_loader, test_loader, epochs=10):\n",
    "    for i in range(1, epochs+1):\n",
    "        print(f\"Epoch: {i}\")\n",
    "        losses = []\n",
    "        its = 0\n",
    "        for X, Y in tqdm(train_loader):\n",
    "            model.zero_grad()\n",
    "            \n",
    "            X = torch.Tensor(X).to(device).long()\n",
    "            Y = torch.FloatTensor(Y).to(device)\n",
    "            preds = model(X)\n",
    "            loss = loss_fn(preds, Y)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            its += 1\n",
    "            if its > 33570:\n",
    "                break\n",
    "            if its % 1000 == 0:\n",
    "                clear_output(wait=True)\n",
    "                print(f\"Train Loss: {torch.tensor(losses).mean():.3f}\")\n",
    "        Compare(model, loss_fn, test_loader)\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=1\n",
    "learning_rate = 1e-3\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "lstm_classifier = LSTMClassifier(128, 75, 35181, 17).to(device)\n",
    "optimizer = torch.optim.SGD(lstm_classifier.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33018it [04:06, 135.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 18114870.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33570it [04:10, 133.79it/s]\n",
      "7194it [00:40, 175.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 18141840.000\n",
      "Validation Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "TrainingLoop(lstm_classifier, loss_fn, optimizer, train_loader, test_loader, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lstm_classifier, \"./LSTM_NER.pth\")\n",
    "model = torch.load(\"./LSTM_NER.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peter B-tim\n",
      "Navarro, B-tim\n",
      "the B-tim\n",
      "White B-tim\n",
      "House B-tim\n",
      "director B-tim\n",
      "of B-tim\n",
      "trade B-tim\n",
      "and B-tim\n",
      "manufacturing B-tim\n",
      "policy B-tim\n",
      "of B-tim\n",
      "U.S, B-tim\n",
      "said B-tim\n",
      "in B-tim\n",
      "an B-tim\n",
      "interview B-tim\n",
      "on B-tim\n",
      "Sunday B-tim\n",
      "morning B-tim\n",
      "that B-tim\n",
      "the B-tim\n",
      "White B-tim\n",
      "House B-tim\n",
      "was B-tim\n",
      "working B-tim\n",
      "to B-tim\n",
      "prepare B-tim\n",
      "for B-tim\n",
      "the B-tim\n",
      "possibility B-tim\n",
      "of B-tim\n",
      "a B-tim\n",
      "second B-tim\n",
      "wave B-tim\n",
      "of B-tim\n",
      "the B-tim\n",
      "coronavirus B-tim\n",
      "in B-tim\n",
      "the B-tim\n",
      "fall, B-tim\n",
      "though B-tim\n",
      "he B-tim\n",
      "said B-tim\n",
      "it B-tim\n",
      "wouldn't B-tim\n",
      "necessarily B-tim\n",
      "come B-tim\n"
     ]
    }
   ],
   "source": [
    "def predict(sentence, model, vocab, tag_map):\n",
    "    s = [vocab[token] if token in vocab else vocab['UNK'] for token in sentence.split(' ')]\n",
    "    batch_data = np.ones((1, len(s)))\n",
    "    batch_data[0][:] = s\n",
    "    sentence = torch.Tensor(batch_data).to(device).long()\n",
    "    output = model(sentence)\n",
    "    outputs = output.argmax(dim=2)\n",
    "    labels = list(tag_map.keys())\n",
    "    pred = []\n",
    "    for i in range(len(outputs[0])):\n",
    "        idx = outputs[0][i] \n",
    "        pred_label = labels[idx]\n",
    "        pred.append(pred_label)\n",
    "    return pred\n",
    "    \n",
    "sentence = \"Peter Navarro, the White House director of trade and manufacturing policy of U.S, said in an interview on Sunday morning that the White House was working to prepare for the possibility of a second wave of the coronavirus in the fall, though he said it wouldn't necessarily come\"\n",
    "s = [vocab[token] if token in vocab else vocab['UNK'] for token in sentence.split(' ')]\n",
    "predictions = predict(sentence, lstm_classifier, vocab, tag_map)\n",
    "for x,y in zip(sentence.split(' '), predictions):\n",
    "    if y != 'O':\n",
    "        print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
